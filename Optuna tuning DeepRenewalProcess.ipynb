{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "\n",
    "def seed_everything():\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "    mx.random.seed(42)\n",
    "    \n",
    "seed_everything()\n",
    "\n",
    "from deeprenewal._datasets import get_dataset\n",
    "from gluonts.dataset.util import to_pandas\n",
    "from deeprenewal._estimator import DeepRenewalEstimator\n",
    "from deeprenewal._evaluator import IntermittentEvaluator\n",
    "from gluonts.model.deepar import DeepAREstimator\n",
    "from gluonts.distribution.neg_binomial import NegativeBinomialOutput\n",
    "from gluonts.distribution.student_t import StudentTOutput\n",
    "from gluonts.model.r_forecast import RForecastPredictor\n",
    "from gluonts.model.prophet import ProphetPredictor\n",
    "from gluonts.evaluation import Evaluator\n",
    "from gluonts.trainer import Trainer\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions \n",
    "\n",
    "import mxnet as mx\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "from argparse import ArgumentParser\n",
    "from gluonts.model.forecast import SampleForecast\n",
    "from croston import croston\n",
    "from fbprophet import Prophet\n",
    "from pathlib import Path\n",
    "from gluonts.model.predictor import Predictor\n",
    "import pandas as pd\n",
    "\n",
    "import optuna\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: manujosephv (use `wandb login --relogin` to force relogin)\n",
      "wandb: Tracking run with wandb version 0.10.1\n",
      "wandb: Run data is saved locally in wandb\\run-20200920_164455-93tpu0xr\n",
      "wandb: Syncing run OptunaRunDeepRenewal_v2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/manujosephv/DeepRenewal\" target=\"_blank\">https://app.wandb.ai/manujosephv/DeepRenewal</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/manujosephv/DeepRenewal/runs/93tpu0xr\" target=\"_blank\">https://app.wandb.ai/manujosephv/DeepRenewal/runs/93tpu0xr</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(93tpu0xr)</h1><p></p><iframe src=\"https://app.wandb.ai/manujosephv/DeepRenewal/runs/93tpu0xr\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1d11e3de8d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(name=\"OptunaRunDeepRenewal_v2\", project =\"DeepRenewal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_epoch_map = {1e-5: 25, 1e-4: 20, 1e-3: 15, 1e-2: 10, 1e-1: 5}\n",
    "# lr_epoch_map = {1e-5: 3, 1e-4: 3, 1e-3: 3, 1e-2: 3, 1e-1: 3}\n",
    "\n",
    "\n",
    "def get_trainer_from_trial(trial):\n",
    "    lr = trial.suggest_categorical(\"lr\", [1e-5, 1e-4, 1e-3, 1e-2, 1e-1])\n",
    "    # epoch_multiplier = 1\n",
    "    epoch_multiplier = trial.suggest_int(\"epoch_multiplier\", 1, 3)\n",
    "    epochs = lr_epoch_map[lr] * epoch_multiplier\n",
    "    bs = trial.suggest_categorical(\"batch_size\", [32, 64, 128, 256])\n",
    "    clip_gradient = trial.suggest_uniform(\"clip_gradient\", 5, 10)\n",
    "    weight_decay = trial.suggest_categorical(\"weight_decay\", [1e-5, 1e-4, 1e-3, 1e-2])\n",
    "    trainer = Trainer(ctx=mx.context.gpu(0),\n",
    "        learning_rate=lr,\n",
    "        epochs=epochs,\n",
    "        num_batches_per_epoch=100,\n",
    "        batch_size=bs,\n",
    "        clip_gradient=clip_gradient,\n",
    "        weight_decay=weight_decay,\n",
    "    )\n",
    "    return trainer\n",
    "\n",
    "\n",
    "def get_deeprenewal_from_trial(trial, trainer):\n",
    "    context_length_multiplier = trial.suggest_categorical(\n",
    "        \"context_length_multiplier\", [1, 2, 3, 4]\n",
    "    )\n",
    "    context_length = context_length_multiplier * prediction_length\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 2, 5)\n",
    "    num_lags = trial.suggest_int(\"num_lags\", 0, 12)\n",
    "    lags_seq = [] if num_lags==0 else np.arange(1,num_lags+1).tolist()\n",
    "    num_cells = trial.suggest_categorical(\"num_cells\", [32, 64, 128])\n",
    "    cell_type = trial.suggest_categorical(\"cell_type\", [\"lstm\", \"gru\"])\n",
    "    dropout_rate = trial.suggest_int(\"dropout\", 1, 5) * 1e-1\n",
    "    estimator = DeepRenewalEstimator(\n",
    "        prediction_length=prediction_length,\n",
    "        context_length=context_length,\n",
    "        num_layers=num_layers,\n",
    "        num_cells=num_cells,\n",
    "        cell_type=cell_type,\n",
    "        dropout_rate=dropout_rate,\n",
    "        scaling=True,\n",
    "        lags_seq=lags_seq,\n",
    "        freq=\"1D\", ##Freq,\n",
    "        use_feat_dynamic_real=args.use_feat_dynamic_real,\n",
    "        use_feat_static_cat=args.use_feat_static_cat,\n",
    "        use_feat_static_real=args.use_feat_static_real,\n",
    "        cardinality=cardinality,\n",
    "        trainer=trainer,\n",
    "        )\n",
    "    return estimator\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    trainer = get_trainer_from_trial(trial)\n",
    "    estimator = get_deeprenewal_from_trial(trial, trainer)\n",
    "    try:\n",
    "        predictor = estimator.train(train_ds, test_ds)\n",
    "        # ### Generating forecasts\n",
    "        forecast_it, ts_it = make_evaluation_predictions(\n",
    "            dataset=test_ds, predictor=predictor, num_samples=100\n",
    "        )\n",
    "\n",
    "        tss = list(tqdm(ts_it, total=len(test_ds)))\n",
    "        forecasts = list(tqdm(forecast_it, total=len(test_ds)))\n",
    "        # ### Local performance validation\n",
    "        evaluator = IntermittentEvaluator(quantiles=[0.5])\n",
    "        agg_metrics, item_metrics = evaluator(\n",
    "            iter(tss), iter(forecasts), num_series=len(test_ds)\n",
    "        )\n",
    "        \n",
    "        mase = agg_metrics[\"MASE\"]\n",
    "        cum_mase = agg_metrics[\"cumMASE\"]\n",
    "        trial.set_user_attr(\"MASE\",mase)\n",
    "        wandb.log({\"MASE\": mase,\n",
    "                  \"cumMASE\": cum_mase})\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "        trial.set_user_attr(\"exception\", e)\n",
    "        cum_mase = 1e20\n",
    "        wandb.log({\"MASE\": 1e20,\n",
    "                  \"cumMASE\": 1e20})\n",
    "    return cum_mase\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"-f\", \"--fff\", help=\"a dummy argument to fool ipython\", default=\"1\")\n",
    "\n",
    "# add PROGRAM level args\n",
    "parser.add_argument('--project-name', type=str, default='deep_renewal_processes')\n",
    "parser.add_argument('--experiment-tag', type=str, default='deep_renewal_process')\n",
    "parser.add_argument('--use-cuda', type=bool, default=True)\n",
    "parser.add_argument('--use-wandb', type=bool, default=True)\n",
    "parser.add_argument('--log-gradients', type=bool, default=True)\n",
    "parser.add_argument('--run-optuna-sweep', type=bool, default=True)\n",
    "parser.add_argument('--datasource', type=str, default=\"retail_dataset\")\n",
    "parser.add_argument('--model-save-dir', type=str, default=\"models\")\n",
    "\n",
    "# Trainer specific args\n",
    "parser.add_argument('--batch_size', type=int, default=256)\n",
    "parser.add_argument('--learning-rate', type=float, default=1e-5)\n",
    "parser.add_argument('--max-epochs', type=int, default=25)\n",
    "parser.add_argument('--number-of-batches-per-epoch', type=int, default=100)\n",
    "parser.add_argument('--clip-gradient', type=float, default=10)\n",
    "parser.add_argument('--weight-decay', type=float, default=1e-8)\n",
    "\n",
    "\n",
    "# Model specific args\n",
    "parser.add_argument('--context-length-multiplier', type=int, default=2)\n",
    "parser.add_argument('--num-layers', type=int, default=4)\n",
    "parser.add_argument('--num-cells', type=int, default=128)\n",
    "parser.add_argument('--cell-type', type=str, default=\"gru\")\n",
    "#p% are dropped and set to zero\n",
    "parser.add_argument('--dropout-rate', type=float, default=0.3)\n",
    "parser.add_argument('--use-feat-dynamic-real', type=bool, default=True)\n",
    "parser.add_argument('--use-feat-static-cat', type=bool, default=True)\n",
    "parser.add_argument('--use-feat-static-real', type=bool, default=False)\n",
    "parser.add_argument('--scaling', type=bool, default=True)\n",
    "parser.add_argument('--num-parallel-samples', type=int, default=100)\n",
    "parser.add_argument('--num-lags', type=int, default=1)\n",
    "#Only for Deep Renewal Processes\n",
    "parser.add_argument('--forecast-type', type=str, default=\"flat\")\n",
    "#Only for Deep AR\n",
    "parser.add_argument('--distr-output', type=str, default=\"student_t\") #neg_binomial\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    "is_gpu = mx.context.num_gpus()>0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset(args.datasource, regenerate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_length = dataset.metadata.prediction_length\n",
    "freq = dataset.metadata.freq\n",
    "cardinality = ast.literal_eval(dataset.metadata.feat_static_cat[0].cardinality)\n",
    "train_ds = dataset.train\n",
    "test_ds = dataset.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-09-20 16:59:13,282] A new study created in memory with name: no-name-ba6a4726-c905-4ae8-bcbd-7029453de8d0\n",
      "WARNING:root:You have set `num_workers` to a non zero value, however, currently multiprocessing is not supported on windows and therefore`num_workers will be set to 0.\n",
      "WARNING:root:You have set `num_workers` to a non zero value, however, currently multiprocessing is not supported on windows and therefore`num_workers will be set to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 100/100 [00:40<00:00,  2.48it/s, epoch=1/15, avg_epoch_loss=6.2]\n",
      "70it [00:20,  3.43it/s, epoch=1/15, validation_avg_epoch_loss=6.09]\n",
      "100%|███████████████████████████████████████████████| 100/100 [00:43<00:00,  2.31it/s, epoch=2/15, avg_epoch_loss=6.08]\n",
      "67it [00:18,  3.63it/s, epoch=2/15, validation_avg_epoch_loss=6.04]\n",
      "100%|███████████████████████████████████████████████| 100/100 [00:45<00:00,  2.22it/s, epoch=3/15, avg_epoch_loss=6.08]\n",
      "67it [00:17,  3.84it/s, epoch=3/15, validation_avg_epoch_loss=6.11]\n",
      "100%|███████████████████████████████████████████████| 100/100 [00:43<00:00,  2.30it/s, epoch=4/15, avg_epoch_loss=6.07]\n",
      "70it [00:17,  4.07it/s, epoch=4/15, validation_avg_epoch_loss=6.04]\n",
      "100%|███████████████████████████████████████████████| 100/100 [00:45<00:00,  2.18it/s, epoch=5/15, avg_epoch_loss=6.02]\n",
      "66it [00:17,  3.79it/s, epoch=5/15, validation_avg_epoch_loss=6.04]\n",
      "100%|███████████████████████████████████████████████| 100/100 [00:42<00:00,  2.34it/s, epoch=6/15, avg_epoch_loss=6.04]\n",
      "68it [00:20,  3.39it/s, epoch=6/15, validation_avg_epoch_loss=6.01]\n",
      "100%|███████████████████████████████████████████████| 100/100 [00:44<00:00,  2.26it/s, epoch=7/15, avg_epoch_loss=5.99]\n",
      "63it [00:16,  3.80it/s, epoch=7/15, validation_avg_epoch_loss=6.03]\n",
      "100%|███████████████████████████████████████████████| 100/100 [00:43<00:00,  2.32it/s, epoch=8/15, avg_epoch_loss=6.04]\n",
      "64it [00:16,  3.86it/s, epoch=8/15, validation_avg_epoch_loss=6.06]\n",
      "100%|███████████████████████████████████████████████| 100/100 [00:41<00:00,  2.43it/s, epoch=9/15, avg_epoch_loss=6.04]\n",
      "67it [00:17,  3.75it/s, epoch=9/15, validation_avg_epoch_loss=6.03]\n",
      "100%|██████████████████████████████████████████████| 100/100 [00:41<00:00,  2.39it/s, epoch=10/15, avg_epoch_loss=6.03]\n",
      "66it [00:16,  4.12it/s, epoch=10/15, validation_avg_epoch_loss=6]   \n",
      "100%|█████████████████████████████████████████████████| 100/100 [00:43<00:00,  2.30it/s, epoch=11/15, avg_epoch_loss=6]\n",
      "66it [00:19,  3.36it/s, epoch=11/15, validation_avg_epoch_loss=6.03]\n",
      "100%|██████████████████████████████████████████████| 100/100 [00:46<00:00,  2.16it/s, epoch=12/15, avg_epoch_loss=6.02]\n",
      "65it [00:19,  3.41it/s, epoch=12/15, validation_avg_epoch_loss=6.05]\n",
      "100%|██████████████████████████████████████████████| 100/100 [00:43<00:00,  2.31it/s, epoch=13/15, avg_epoch_loss=6.02]\n",
      "69it [00:16,  4.10it/s, epoch=13/15, validation_avg_epoch_loss=6.03]\n",
      "100%|██████████████████████████████████████████████| 100/100 [00:39<00:00,  2.52it/s, epoch=14/15, avg_epoch_loss=6.01]\n",
      "64it [00:15,  4.13it/s, epoch=14/15, validation_avg_epoch_loss=5.96]\n",
      "100%|█████████████████████████████████████████████████| 100/100 [00:39<00:00,  2.56it/s, epoch=15/15, avg_epoch_loss=6]\n",
      "65it [00:15,  4.14it/s, epoch=15/15, validation_avg_epoch_loss=6]   \n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1822/1822 [00:00<00:00, 1996.58it/s]\n",
      "  0%|                                                                                         | 0/1822 [00:00<?, ?it/s]WARNING:root:You have set `num_workers` to a non zero value, however, currently multiprocessing is not supported on windows and therefore`num_workers will be set to 0.\n",
      "D:\\Playground\\ts_research\\deep_renewal\\deeprenewal\\deeprenewal\\_forecast_generator.py:69: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in true_divide\n",
      "\n",
      "D:\\Playground\\ts_research\\deep_renewal\\deeprenewal\\deeprenewal\\_forecast_generator.py:69: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1822/1822 [01:00<00:00, 30.02it/s]\n",
      "Running evaluation: 100%|█████████████████████████████████████████████████████████| 1822/1822 [00:11<00:00, 152.26it/s]\n",
      "[I 2020-09-20 17:15:36,042] Trial 0 finished with value: 36.600745306903534 and parameters: {'lr': 0.001, 'epoch_multiplier': 1, 'batch_size': 32, 'clip_gradient': 5.664767097574645, 'weight_decay': 0.0001, 'context_length_multiplier': 3, 'num_layers': 3, 'num_lags': 6, 'num_cells': 32, 'cell_type': 'gru', 'dropout': 1}. Best is trial 0 with value: 36.600745306903534.\n",
      "WARNING:root:You have set `num_workers` to a non zero value, however, currently multiprocessing is not supported on windows and therefore`num_workers will be set to 0.\n",
      "WARNING:root:You have set `num_workers` to a non zero value, however, currently multiprocessing is not supported on windows and therefore`num_workers will be set to 0.\n",
      "100%|███████████████████████████████████████████████| 100/100 [02:14<00:00,  1.34s/it, epoch=1/10, avg_epoch_loss=6.14]\n",
      "9it [00:09,  1.06s/it, epoch=1/10, validation_avg_epoch_loss=6.01]\n",
      "100%|███████████████████████████████████████████████| 100/100 [02:11<00:00,  1.32s/it, epoch=2/10, avg_epoch_loss=6.04]\n",
      "10it [00:09,  1.06it/s, epoch=2/10, validation_avg_epoch_loss=6.06]\n",
      "100%|███████████████████████████████████████████████| 100/100 [02:11<00:00,  1.31s/it, epoch=3/10, avg_epoch_loss=6.02]\n",
      "10it [00:09,  1.03it/s, epoch=3/10, validation_avg_epoch_loss=6.04]\n",
      "100%|███████████████████████████████████████████████| 100/100 [02:31<00:00,  1.51s/it, epoch=4/10, avg_epoch_loss=6.01]\n",
      "9it [00:14,  1.63s/it, epoch=4/10, validation_avg_epoch_loss=6.02]\n",
      "100%|██████████████████████████████████████████████████| 100/100 [02:28<00:00,  1.49s/it, epoch=5/10, avg_epoch_loss=6]\n",
      "9it [00:09,  1.09s/it, epoch=5/10, validation_avg_epoch_loss=6.04]\n",
      "100%|███████████████████████████████████████████████| 100/100 [02:22<00:00,  1.42s/it, epoch=6/10, avg_epoch_loss=5.99]\n",
      "9it [00:09,  1.10s/it, epoch=6/10, validation_avg_epoch_loss=5.96]\n",
      "100%|██████████████████████████████████████████████████| 100/100 [02:17<00:00,  1.38s/it, epoch=7/10, avg_epoch_loss=6]\n",
      "9it [00:09,  1.06s/it, epoch=7/10, validation_avg_epoch_loss=6.01]\n",
      "100%|███████████████████████████████████████████████| 100/100 [02:21<00:00,  1.42s/it, epoch=8/10, avg_epoch_loss=5.98]\n",
      "10it [00:09,  1.01it/s, epoch=8/10, validation_avg_epoch_loss=5.97]\n",
      "100%|███████████████████████████████████████████████| 100/100 [02:21<00:00,  1.42s/it, epoch=9/10, avg_epoch_loss=5.98]\n",
      "9it [00:09,  1.08s/it, epoch=9/10, validation_avg_epoch_loss=5.99]\n",
      "100%|██████████████████████████████████████████████| 100/100 [02:14<00:00,  1.34s/it, epoch=10/10, avg_epoch_loss=5.97]\n",
      "9it [00:09,  1.04s/it, epoch=10/10, validation_avg_epoch_loss=5.99]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1822/1822 [00:00<00:00, 2283.59it/s]\n",
      "  0%|                                                                                         | 0/1822 [00:00<?, ?it/s]WARNING:root:You have set `num_workers` to a non zero value, however, currently multiprocessing is not supported on windows and therefore`num_workers will be set to 0.\n",
      "D:\\Playground\\ts_research\\deep_renewal\\deeprenewal\\deeprenewal\\_forecast_generator.py:69: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in true_divide\n",
      "\n",
      "D:\\Playground\\ts_research\\deep_renewal\\deeprenewal\\deeprenewal\\_forecast_generator.py:69: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1822/1822 [00:17<00:00, 101.28it/s]\n",
      "Running evaluation: 100%|█████████████████████████████████████████████████████████| 1822/1822 [00:11<00:00, 159.47it/s]\n",
      "[I 2020-09-20 17:41:03,488] Trial 1 finished with value: 36.518890267362536 and parameters: {'lr': 0.01, 'epoch_multiplier': 1, 'batch_size': 256, 'clip_gradient': 7.803426926065766, 'weight_decay': 0.001, 'context_length_multiplier': 2, 'num_layers': 3, 'num_lags': 4, 'num_cells': 64, 'cell_type': 'gru', 'dropout': 2}. Best is trial 1 with value: 36.518890267362536.\n",
      "WARNING:root:You have set `num_workers` to a non zero value, however, currently multiprocessing is not supported on windows and therefore`num_workers will be set to 0.\n",
      "WARNING:root:You have set `num_workers` to a non zero value, however, currently multiprocessing is not supported on windows and therefore`num_workers will be set to 0.\n",
      "100%|███████████████████████████████████████████████| 100/100 [01:34<00:00,  1.06it/s, epoch=1/30, avg_epoch_loss=6.16]\n",
      "19it [00:13,  1.39it/s, epoch=1/30, validation_avg_epoch_loss=6.06]\n",
      "100%|███████████████████████████████████████████████| 100/100 [01:36<00:00,  1.04it/s, epoch=2/30, avg_epoch_loss=6.07]\n",
      "17it [00:12,  1.35it/s, epoch=2/30, validation_avg_epoch_loss=6.08]\n",
      "100%|███████████████████████████████████████████████| 100/100 [01:37<00:00,  1.03it/s, epoch=3/30, avg_epoch_loss=6.06]\n",
      "18it [00:12,  1.44it/s, epoch=3/30, validation_avg_epoch_loss=6.03]\n",
      "100%|███████████████████████████████████████████████| 100/100 [01:36<00:00,  1.04it/s, epoch=4/30, avg_epoch_loss=6.06]\n",
      "17it [00:13,  1.26it/s, epoch=4/30, validation_avg_epoch_loss=6.07]\n",
      "100%|███████████████████████████████████████████████| 100/100 [01:36<00:00,  1.03it/s, epoch=5/30, avg_epoch_loss=6.03]\n",
      "17it [00:11,  1.48it/s, epoch=5/30, validation_avg_epoch_loss=5.99]\n",
      "[W 2020-09-20 17:50:08,283] Trial 2 failed because of the following error: MXNetError('Error in operator deeprenewaltrainingnetwork3__mul1: [17:50:08] c:\\\\jenkins\\\\workspace\\\\mxnet-tag\\\\mxnet\\\\src\\\\operator\\\\tensor\\\\../elemwise_op_common.h:135: Check failed: assign(&dattr, vec.at(i)): Incompatible attr in node deeprenewaltrainingnetwork3__mul1 at 1-th input: expected [156], got [1,156]',)\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\miniconda3\\envs\\timeseries\\lib\\site-packages\\optuna\\study.py\", line 778, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-9-a6a70c9da8c2>\", line 78, in objective\n",
      "    raise e\n",
      "  File \"<ipython-input-9-a6a70c9da8c2>\", line 58, in objective\n",
      "    predictor = estimator.train(train_ds, test_ds)\n",
      "  File \"D:\\miniconda3\\envs\\timeseries\\lib\\site-packages\\gluonts\\model\\estimator.py\", line 252, in train\n",
      "    training_data, validation_data, num_workers, num_prefetch, **kwargs\n",
      "  File \"D:\\miniconda3\\envs\\timeseries\\lib\\site-packages\\gluonts\\model\\estimator.py\", line 231, in train_model\n",
      "    validation_iter=validation_data_loader,\n",
      "  File \"D:\\miniconda3\\envs\\timeseries\\lib\\site-packages\\gluonts\\trainer\\_base.py\", line 306, in __call__\n",
      "    epoch_no, validation_iter, is_training=False\n",
      "  File \"D:\\miniconda3\\envs\\timeseries\\lib\\site-packages\\gluonts\\trainer\\_base.py\", line 238, in loop\n",
      "    output = net(*inputs)\n",
      "  File \"D:\\miniconda3\\envs\\timeseries\\lib\\site-packages\\mxnet\\gluon\\block.py\", line 693, in __call__\n",
      "    out = self.forward(*args)\n",
      "  File \"D:\\miniconda3\\envs\\timeseries\\lib\\site-packages\\mxnet\\gluon\\block.py\", line 1148, in forward\n",
      "    return self._call_cached_op(x, *args)\n",
      "  File \"D:\\miniconda3\\envs\\timeseries\\lib\\site-packages\\mxnet\\gluon\\block.py\", line 1020, in _call_cached_op\n",
      "    out = self._cached_op(*cargs)\n",
      "  File \"D:\\miniconda3\\envs\\timeseries\\lib\\site-packages\\mxnet\\_ctypes\\ndarray.py\", line 170, in __call__\n",
      "    ctypes.byref(out_stypes)))\n",
      "  File \"D:\\miniconda3\\envs\\timeseries\\lib\\site-packages\\mxnet\\base.py\", line 255, in check_call\n",
      "    raise MXNetError(py_str(_LIB.MXGetLastError()))\n",
      "mxnet.base.MXNetError: Error in operator deeprenewaltrainingnetwork3__mul1: [17:50:08] c:\\jenkins\\workspace\\mxnet-tag\\mxnet\\src\\operator\\tensor\\../elemwise_op_common.h:135: Check failed: assign(&dattr, vec.at(i)): Incompatible attr in node deeprenewaltrainingnetwork3__mul1 at 1-th input: expected [156], got [1,156]\n"
     ]
    },
    {
     "ename": "MXNetError",
     "evalue": "Error in operator deeprenewaltrainingnetwork3__mul1: [17:50:08] c:\\jenkins\\workspace\\mxnet-tag\\mxnet\\src\\operator\\tensor\\../elemwise_op_common.h:135: Check failed: assign(&dattr, vec.at(i)): Incompatible attr in node deeprenewaltrainingnetwork3__mul1 at 1-th input: expected [156], got [1,156]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-ccf951dac026>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"minimize\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of finished trials: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\envs\\timeseries\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m                 self._optimize_sequential(\n\u001b[1;32m--> 328\u001b[1;33m                     \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m                 )\n\u001b[0;32m    330\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\envs\\timeseries\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(self, func, n_trials, timeout, catch, callbacks, gc_after_trial, time_start)\u001b[0m\n\u001b[0;32m    724\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    725\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 726\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_trial_and_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_progress_bar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\envs\\timeseries\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_run_trial_and_callbacks\u001b[1;34m(self, func, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[0;32m    753\u001b[0m     ) -> None:\n\u001b[0;32m    754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 755\u001b[1;33m         \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    756\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[0mfrozen_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\envs\\timeseries\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(self, func, catch, gc_after_trial)\u001b[0m\n\u001b[0;32m    776\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 778\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    779\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Trial {} pruned. {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial_number\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-a6a70c9da8c2>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     76\u001b[0m                   \"cumMASE\": cum_mase})\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m         \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_user_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"exception\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mcum_mase\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-a6a70c9da8c2>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_deeprenewal_from_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mpredictor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[1;31m# ### Generating forecasts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         forecast_it, ts_it = make_evaluation_predictions(\n",
      "\u001b[1;32mD:\\miniconda3\\envs\\timeseries\\lib\\site-packages\\gluonts\\model\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, training_data, validation_data, num_workers, num_prefetch, **kwargs)\u001b[0m\n\u001b[0;32m    250\u001b[0m     ) -> Predictor:\n\u001b[0;32m    251\u001b[0m         return self.train_model(\n\u001b[1;32m--> 252\u001b[1;33m             \u001b[0mtraining_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_prefetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m         ).predictor\n",
      "\u001b[1;32mD:\\miniconda3\\envs\\timeseries\\lib\\site-packages\\gluonts\\model\\estimator.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(self, training_data, validation_data, num_workers, num_prefetch, **kwargs)\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[0minput_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_hybrid_forward_input_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrained_net\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mtrain_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_data_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m             \u001b[0mvalidation_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_data_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m         )\n\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\envs\\timeseries\\lib\\site-packages\\gluonts\\trainer\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, net, input_names, train_iter, validation_iter)\u001b[0m\n\u001b[0;32m    304\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mis_validation_available\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m                         epoch_loss = loop(\n\u001b[1;32m--> 306\u001b[1;33m                             \u001b[0mepoch_no\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m                         )\n\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\envs\\timeseries\\lib\\site-packages\\gluonts\\trainer\\_base.py\u001b[0m in \u001b[0;36mloop\u001b[1;34m(epoch_no, batch_iter, is_training)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m                             \u001b[1;32mwith\u001b[0m \u001b[0mmx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m                                 \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m                                 \u001b[1;31m# network can returns several outputs, the first being always the loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\envs\\timeseries\\lib\\site-packages\\mxnet\\gluon\\block.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    691\u001b[0m             \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\envs\\timeseries\\lib\\site-packages\\mxnet\\gluon\\block.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m   1146\u001b[0m                                      'Find all contexts = {}'.format(ctx_set))\n\u001b[0;32m   1147\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1148\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_cached_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1149\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\envs\\timeseries\\lib\\site-packages\\mxnet\\gluon\\block.py\u001b[0m in \u001b[0;36m_call_cached_op\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1018\u001b[0m                     \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_finish_deferred_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m                     \u001b[0mcargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1020\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cached_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1021\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNDArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1022\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\envs\\timeseries\\lib\\site-packages\\mxnet\\_ctypes\\ndarray.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m             ctypes.byref(out_stypes)))\n\u001b[0m\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moriginal_output\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\envs\\timeseries\\lib\\site-packages\\mxnet\\base.py\u001b[0m in \u001b[0;36mcheck_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    253\u001b[0m     \"\"\"\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mMXNetError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMXGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMXNetError\u001b[0m: Error in operator deeprenewaltrainingnetwork3__mul1: [17:50:08] c:\\jenkins\\workspace\\mxnet-tag\\mxnet\\src\\operator\\tensor\\../elemwise_op_common.h:135: Check failed: assign(&dattr, vec.at(i)): Incompatible attr in node deeprenewaltrainingnetwork3__mul1 at 1-th input: expected [156], got [1,156]"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "df = study.trials_dataframe()\n",
    "# if len(filters.values())>0:\n",
    "#     tag = \"|\".join(filters.values())\n",
    "# else:\n",
    "#     tag = 'all'\n",
    "tag = 'interm'\n",
    "df.to_csv(f\"{tag}_deeprenewal_study_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = r'Trial\\s(\\d{1,2}) finished with value:\\s(\\d.\\d+) and parameters: ({.+})'\n",
    "trials = []\n",
    "values=[]\n",
    "params=[]\n",
    "with open(\"temp.txt\",\"r\") as f:\n",
    "    for line in f:\n",
    "        g = re.search(pattern, line)\n",
    "        if g:\n",
    "            trials.append(g.group(1))\n",
    "            values.append(g.group(2))\n",
    "            params.append(g.group(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_df = pd.DataFrame({\"Trial\": trials, \"Value\":values, \"params\": params})\n",
    "trial_df.to_csv(\"interm_rmse_tuning.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:timeseries] *",
   "language": "python",
   "name": "conda-env-timeseries-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
